{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursera Capstone\n",
    "\n",
    "This notebook is dedicated to analysing car crash severity data and building a ML model that can help prevent such accidents by warning users when road conditions are accident-prone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Hello Capstone Project Course!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding\n",
    "\n",
    "The idea behind this project is to develop a system that will warn road-users of the chances and severity of an accident occuring to them. The four factors that determine an accident are weather and road conditions, vehicle characteristics and finally human error. It is easy to deduce that weather and road conditions will have a meaningful impact on the chances and severity of an accident. For vehicle characteristics: a motorbike will have increased chances of a severe accident most of the time due to decreased protection when compared to a car for example. All of these factors influence the final result and must be taken into consideration. Human error is difficult to quantify unless the distraction/error made by the driver has been recorded, as well as being diifcult to predict (that would have to besolved with another model with a different set of attributes). We must look for the aforementioned attributes in our dataset, and use them to deduce the severity and chances of accidents happening with varying road, weather and vehicle conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding\n",
    "\n",
    "Extracting the data and displaying it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_collisions = pd.read_csv('Data-Collisions.csv', low_memory=False)\n",
    "df_collisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is all car-accidents in Seattle; provided by SPD and recorded by Traffic Records\n",
    "\n",
    "All the attributes that are not a direct result of the accident taking place should be considered. We can only use the set of attributes that were present before the accident happened. We cannot predict accidents with data that is a direct result of that accident. \n",
    "As previously mentioned, road, weather & vehicle conditions are determining factors of an accident; as well as location and location type. Human error is another one, but it is almost impossible to determine the chances of the driver being distracted with this dataset. It is only once the accident has happned that we may find out if there was human error involved.\n",
    "\n",
    "Initially, just by looking at the metadata, the attributes I would use are:\n",
    "\n",
    "ADDRTYPE: Alley, Block, Intersection\n",
    "LOCATION: General location of collision\n",
    "JUNCTIONTYPE: Category of junction at which the collision took place\n",
    "WEATHER: Weather description at the location and during the time of the collision\n",
    "ROADCOND: Road condition at the location and during the time of the collision\n",
    "LIGHTCOND: Light conditions at the location and during the time of the collision\n",
    "INDCTTM: Date and time of incident. Accidents at night are more likely to be severe etc. Accidents during rush hour are more likely to occur.....\n",
    "\n",
    "PERSONCOUNT, PEDCOUNT, PEDCYLCOUNT, VEHCOUNT, INJURIES, SERIOUSINJURIES, FATALITIES, HITPARKEDCAR are all attributes that easily help in deducing accident severity. But because this is a predictive model, and these attributes cannot be known before the actual accident happens, they are meaningless when trying to predict accident severity and probability. For example, instead of VEHCOUNT, traffic density per location would be an attribute that we could know beforehand and therfore a meaningful attribute for the model. The same for the other attributes. How many people were travelling in the car that had the accident would be useful as well, as it is easily known how many people you are taking in your car before the actual trip. I will not go through the explanation of every single attribute; the main idea is to select attributes that are known and can be qauntified before the accident happened and taht directly contribute to the final result (accident or not and its severity). Data that is recorded as a result of the accident is obviously not useful for predictions.\n",
    "\n",
    "Our label and what we are trying to predict is SEVERITYCODE, which displays whether there was an accident and its severity. This is what we will try to predict in the future. \n",
    "\n",
    "We must also look at each column (attribute) of the dataset and determine whether data is skewed, biased or missing. We must correct these issues if our model is to be precise. We can also do statistical tests as an initial screening to determine correlations between different attributes and their respective labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Dropping useless columns as well as inspecting for missing values and checking for bias\n",
    "\n",
    "\n",
    "df = df_collisions[['ADDRTYPE','LOCATION','JUNCTIONTYPE','WEATHER','ROADCOND','LIGHTCOND','INCDTTM','SEVERITYCODE']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['JUNCTIONTYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['LOCATION', 'INCDTTM'], axis=1 ,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WEATHER'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LIGHTCOND'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ROADCOND'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ADDRTYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SEVERITYCODE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the Time and Date of the incidents that some entries contain the time of day whereas some contain just the day it occured. I will delete the time of day data and just concentrate on the dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"INCDTTM\"]= df[\"INCDTTM\"].str.split(\" \", n = 1, expand = True) ## I REMOVE THE TIME FROM THE DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['INCDTTM'].value_counts() ###We can see it worked! Now remove the year!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[\"INCDTTM\"]= df[\"INCDTTM\"].str.rsplit(\"/\", n = 1, expand = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['INCDTTM'].value_counts() ### IDEALLY I WOULD SPLIT DATES INTO 3 CATEGORIES: HOLIDAYS & FESTIVES, WORK DAYS, WEEKEND. DAYS IMMEDIATELY AFTER\n",
    "## A BIG HOLIDAY EVENT ALSO NOTED. ESPECIALLY EVENING AFTER BIG NATIONAL/LOCAL EVENTS (USUALLY PPL DRIVING HOME IN THE EVENING AFTER THE CELEBRATION)\n",
    "\n",
    "##I WOULD ALSO USE THE TIME DATA TO FIGURE OUT IF THE ACCIDENT OCCURED AT NIGHT, RUSH HOUR or whether the accident occured outside of these times\n",
    "### making these three categories. RUSH HOUR =more traffic, night time= less visibilty and higher cahnce of user error due to tiredness or alcohol related... \n",
    "### THE REMAINING CATEGORY WOULD BE THE REMAINDER OF NIGHT & AND RUSH HOUR CATEGORIES\n",
    "### Due to time constraints I will only use the dates without the years, and I will not create extra categories (although this would be the best practice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns= ['ADDRTYPE','JUNCTIONTYPE','WEATHER','ROADCOND','LIGHTCOND'])\n",
    "df\n",
    "df['SEVERITYCODE'] = df['SEVERITYCODE'].apply(lambda x:0 if x==1 else x)\n",
    "df['SEVERITYCODE'] = df['SEVERITYCODE'].apply(lambda x:1if x==2 else x) ## BINARY NOW. 0 = PROPDAMAGE, 1 =INJURY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_maj = df[df.SEVERITYCODE == 0] ## I MUST REDUCE THE BIAS BEFORE SPLITTING\n",
    "df_min = df[df.SEVERITYCODE == 1]\n",
    "\n",
    "df_resampled = resample(df_maj, replace=False, n_samples=58188, random_state=4) \n",
    "df_final= pd.concat([df_resampled, df_min])\n",
    "df_final.SEVERITYCODE.value_counts()  ## WE CAN SEE THAT THE DATA IS NOW UNBIASED. DOWNSIDE ID TAHT WE HAVE LOST DATA IN THE PROCESS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = df[['ADDRTYPE','LOCATION','WEATHER','ROADCOND','LIGHTCOND','INCDTTM']]    ## TRAIN TEST SPLIT!\n",
    "\n",
    "x = df_final.loc[:, df_final.columns != 'SEVERITYCODE'] ##SELECTING ALL COLUMNS EXCEPT FOR SEVERITYCODE WHICH IS OUR LABEL\n",
    "y = df_final['SEVERITYCODE']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{'C' : [0.01, 0.1, 1, 10, 100], 'solver' : ['liblinear','newton-cg','saga', 'sag','lbfgs']}]\n",
    "lr_CV = GridSearchCV(LogisticRegression(), param_grid, cv=5, verbose=True, n_jobs=-1)\n",
    "lr_CV.fit(x_train,y_train)\n",
    "lr_CV_pred = lr_CV.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr_CV_pred[0:999])\n",
    "print(lr_CV.best_estimator_)\n",
    "print(lr_CV.best_score_)\n",
    "print(lr_CV.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=0.1, solver='newton-cg')\n",
    "lr.fit(x_train,y_train)\n",
    "lr.predict(x_test)\n",
    "print(lr.score(x_train, y_train))\n",
    "jaccard_score(y_test, lr.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NOW WIITH SVM\n",
    "from sklearn import svm\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'kernel': ['rbf','linear','poly','sigmoid']}  \n",
    "\n",
    "svmCV = GridSearchCV(svm.SVC(), param_grid, cv=5, verbose=True, n_jobs=-1)\n",
    "svmCV.fit(x_train, y_train)\n",
    "svmCV_pred = svmCV.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(svmCV_pred)\n",
    "print(svmCV.best_estimator_)\n",
    "print(svmCV.best_score_)\n",
    "print(svmCV.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
